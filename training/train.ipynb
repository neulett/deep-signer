{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.python.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(302378,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.load('./preprocessing/keypoints/concatnated_label.npy')\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:01<00:00, 2497.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(302378, 33, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrays = []\n",
    "\n",
    "path = './preprocessing/keypoints/keypoints_save/'\n",
    "\n",
    "for filename in tqdm(os.listdir(path)):\n",
    "    file_path = os.path.join(path, filename)\n",
    "    array = np.load(file_path)\n",
    "    arrays.append(array)\n",
    "\n",
    "combined_array = np.concatenate(arrays, axis=0)\n",
    "\n",
    "combined_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 70, 70, 70], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_data = le.fit_transform(label)\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = np.unique(label)\n",
    "len(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302378, 33, 3)\n",
      "(302378,)\n"
     ]
    }
   ],
   "source": [
    "print(combined_array.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(y_data, num_classes=419)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241902, 33, 3) (60476, 33, 3)\n",
      "(241902, 419) (60476, 419)\n",
      "33 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = combined_array.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(combined_array, y_data, test_size=0.2)\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "print(x_train.shape[1], x_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 33, 64)            17408     \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 33, 128)           98816     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 419)               54051     \n",
      "=================================================================\n",
      "Total params: 597,411\n",
      "Trainable params: 597,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(256, return_sequences=False),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "7560/7560 [==============================] - 106s 14ms/step - loss: 5.4034 - accuracy: 0.0201 - val_loss: 4.9327 - val_accuracy: 0.0460\n",
      "Epoch 2/80\n",
      "7560/7560 [==============================] - 101s 13ms/step - loss: 4.2298 - accuracy: 0.1022 - val_loss: 3.6993 - val_accuracy: 0.1600\n",
      "Epoch 3/80\n",
      "7560/7560 [==============================] - 103s 14ms/step - loss: 3.2747 - accuracy: 0.2235 - val_loss: 2.9043 - val_accuracy: 0.2854\n",
      "Epoch 4/80\n",
      "7560/7560 [==============================] - 103s 14ms/step - loss: 2.7280 - accuracy: 0.3214 - val_loss: 2.6053 - val_accuracy: 0.3448\n",
      "Epoch 5/80\n",
      "7560/7560 [==============================] - 108s 14ms/step - loss: 2.3985 - accuracy: 0.3873 - val_loss: 2.3470 - val_accuracy: 0.4004\n",
      "Epoch 6/80\n",
      "7560/7560 [==============================] - 113s 15ms/step - loss: 2.1631 - accuracy: 0.4371 - val_loss: 2.2797 - val_accuracy: 0.4192\n",
      "Epoch 7/80\n",
      "7560/7560 [==============================] - 114s 15ms/step - loss: 1.9644 - accuracy: 0.4809 - val_loss: 2.0575 - val_accuracy: 0.4663\n",
      "Epoch 8/80\n",
      "7560/7560 [==============================] - 113s 15ms/step - loss: 1.8229 - accuracy: 0.5135 - val_loss: 1.9365 - val_accuracy: 0.4966\n",
      "Epoch 9/80\n",
      "7560/7560 [==============================] - 117s 15ms/step - loss: 1.6910 - accuracy: 0.5441 - val_loss: 1.7543 - val_accuracy: 0.5364\n",
      "Epoch 10/80\n",
      "7560/7560 [==============================] - 114s 15ms/step - loss: 1.5795 - accuracy: 0.5698 - val_loss: 1.6636 - val_accuracy: 0.5582\n",
      "Epoch 11/80\n",
      "7560/7560 [==============================] - 114s 15ms/step - loss: 1.4904 - accuracy: 0.5910 - val_loss: 1.5944 - val_accuracy: 0.5761\n",
      "Epoch 12/80\n",
      "7560/7560 [==============================] - 116s 15ms/step - loss: 1.4095 - accuracy: 0.6103 - val_loss: 1.7158 - val_accuracy: 0.5483\n",
      "Epoch 13/80\n",
      "7560/7560 [==============================] - 113s 15ms/step - loss: 1.3313 - accuracy: 0.6283 - val_loss: 1.5758 - val_accuracy: 0.5839\n",
      "Epoch 14/80\n",
      "7560/7560 [==============================] - 110s 15ms/step - loss: 1.2743 - accuracy: 0.6434 - val_loss: 1.5404 - val_accuracy: 0.5963\n",
      "Epoch 15/80\n",
      "7560/7560 [==============================] - 109s 14ms/step - loss: 1.2161 - accuracy: 0.6574 - val_loss: 1.6013 - val_accuracy: 0.5827\n",
      "Epoch 16/80\n",
      "7560/7560 [==============================] - 111s 15ms/step - loss: 1.1624 - accuracy: 0.6715 - val_loss: 1.4425 - val_accuracy: 0.6214\n",
      "Epoch 17/80\n",
      "7560/7560 [==============================] - 109s 14ms/step - loss: 1.1193 - accuracy: 0.6818 - val_loss: 1.5779 - val_accuracy: 0.5915\n",
      "Epoch 18/80\n",
      "7560/7560 [==============================] - 110s 14ms/step - loss: 1.0762 - accuracy: 0.6928 - val_loss: 1.4209 - val_accuracy: 0.6270\n",
      "Epoch 19/80\n",
      "7560/7560 [==============================] - 101s 13ms/step - loss: 1.0277 - accuracy: 0.7047 - val_loss: 1.3620 - val_accuracy: 0.6450\n",
      "Epoch 20/80\n",
      "7560/7560 [==============================] - 101s 13ms/step - loss: 0.9936 - accuracy: 0.7133 - val_loss: 1.4650 - val_accuracy: 0.6228\n",
      "Epoch 21/80\n",
      "7560/7560 [==============================] - 101s 13ms/step - loss: 0.9619 - accuracy: 0.7222 - val_loss: 1.2682 - val_accuracy: 0.6693\n",
      "Epoch 22/80\n",
      "7560/7560 [==============================] - 102s 13ms/step - loss: 0.9360 - accuracy: 0.7281 - val_loss: 1.2187 - val_accuracy: 0.6839\n",
      "Epoch 23/80\n",
      "7560/7560 [==============================] - 101s 13ms/step - loss: 0.9005 - accuracy: 0.7369 - val_loss: 1.2448 - val_accuracy: 0.6770\n",
      "Epoch 24/80\n",
      "7560/7560 [==============================] - 102s 13ms/step - loss: 0.8807 - accuracy: 0.7435 - val_loss: 1.4161 - val_accuracy: 0.6441\n",
      "Epoch 25/80\n",
      "7560/7560 [==============================] - 101s 13ms/step - loss: 0.8486 - accuracy: 0.7517 - val_loss: 1.2378 - val_accuracy: 0.6779\n",
      "Epoch 26/80\n",
      "7560/7560 [==============================] - 102s 13ms/step - loss: 0.8244 - accuracy: 0.7580 - val_loss: 1.2590 - val_accuracy: 0.6843\n",
      "Epoch 27/80\n",
      "7560/7560 [==============================] - 100s 13ms/step - loss: 0.8013 - accuracy: 0.7639 - val_loss: 1.4880 - val_accuracy: 0.6313\n",
      "Epoch 28/80\n",
      "7560/7560 [==============================] - 102s 13ms/step - loss: 0.7808 - accuracy: 0.7693 - val_loss: 1.1903 - val_accuracy: 0.7000\n",
      "Epoch 29/80\n",
      "7560/7560 [==============================] - 101s 13ms/step - loss: 0.7683 - accuracy: 0.7723 - val_loss: 1.2102 - val_accuracy: 0.6970\n",
      "Epoch 30/80\n",
      "7560/7560 [==============================] - 100s 13ms/step - loss: 0.7473 - accuracy: 0.7787 - val_loss: 1.3332 - val_accuracy: 0.6697\n",
      "Epoch 31/80\n",
      "7560/7560 [==============================] - 102s 13ms/step - loss: 0.7276 - accuracy: 0.7835 - val_loss: 1.1526 - val_accuracy: 0.7086\n",
      "Epoch 32/80\n",
      "7560/7560 [==============================] - 101s 13ms/step - loss: 0.7087 - accuracy: 0.7879 - val_loss: 1.1763 - val_accuracy: 0.7032\n",
      "Epoch 33/80\n",
      "7560/7560 [==============================] - 100s 13ms/step - loss: 0.6894 - accuracy: 0.7932 - val_loss: 1.2776 - val_accuracy: 0.6898\n",
      "Epoch 34/80\n",
      "7560/7560 [==============================] - 101s 13ms/step - loss: 0.6797 - accuracy: 0.7959 - val_loss: 1.1663 - val_accuracy: 0.7134\n",
      "Epoch 35/80\n",
      "7560/7560 [==============================] - 101s 13ms/step - loss: 0.6713 - accuracy: 0.7991 - val_loss: 1.1191 - val_accuracy: 0.7280\n",
      "Epoch 36/80\n",
      "7560/7560 [==============================] - 100s 13ms/step - loss: 0.6573 - accuracy: 0.8022 - val_loss: 1.0777 - val_accuracy: 0.7355\n",
      "Epoch 37/80\n",
      "7560/7560 [==============================] - 100s 13ms/step - loss: 0.6420 - accuracy: 0.8067 - val_loss: 1.2128 - val_accuracy: 0.7068\n",
      "Epoch 38/80\n",
      "7560/7560 [==============================] - 102s 13ms/step - loss: 0.6310 - accuracy: 0.8097 - val_loss: 1.1551 - val_accuracy: 0.7185\n",
      "Epoch 39/80\n",
      "7560/7560 [==============================] - 101s 13ms/step - loss: 0.6204 - accuracy: 0.8129 - val_loss: 1.1394 - val_accuracy: 0.7322\n",
      "Epoch 40/80\n",
      "7560/7560 [==============================] - 99s 13ms/step - loss: 0.6040 - accuracy: 0.8165 - val_loss: 1.3039 - val_accuracy: 0.6961\n",
      "Epoch 41/80\n",
      "7560/7560 [==============================] - 93s 12ms/step - loss: 0.6005 - accuracy: 0.8178 - val_loss: 1.1776 - val_accuracy: 0.7204\n",
      "Epoch 42/80\n",
      "7560/7560 [==============================] - 93s 12ms/step - loss: 0.5869 - accuracy: 0.8217 - val_loss: 1.2324 - val_accuracy: 0.7084\n",
      "Epoch 43/80\n",
      "7560/7560 [==============================] - 93s 12ms/step - loss: 0.5763 - accuracy: 0.8240 - val_loss: 1.1285 - val_accuracy: 0.7371\n",
      "Epoch 44/80\n",
      "7560/7560 [==============================] - 96s 13ms/step - loss: 0.5660 - accuracy: 0.8271 - val_loss: 1.0561 - val_accuracy: 0.7514\n",
      "Epoch 45/80\n",
      "7560/7560 [==============================] - 95s 13ms/step - loss: 0.5574 - accuracy: 0.8294 - val_loss: 1.2783 - val_accuracy: 0.7069\n",
      "Epoch 46/80\n",
      "7560/7560 [==============================] - 96s 13ms/step - loss: 0.5468 - accuracy: 0.8325 - val_loss: 1.1590 - val_accuracy: 0.7302\n",
      "Epoch 47/80\n",
      "7560/7560 [==============================] - 96s 13ms/step - loss: 0.5473 - accuracy: 0.8324 - val_loss: 1.1473 - val_accuracy: 0.7354\n",
      "Epoch 48/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.5325 - accuracy: 0.8363 - val_loss: 1.2826 - val_accuracy: 0.7154\n",
      "Epoch 49/80\n",
      "7560/7560 [==============================] - 96s 13ms/step - loss: 0.5257 - accuracy: 0.8385 - val_loss: 1.0470 - val_accuracy: 0.7600\n",
      "Epoch 50/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.5200 - accuracy: 0.8406 - val_loss: 1.0757 - val_accuracy: 0.7578\n",
      "Epoch 51/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.5093 - accuracy: 0.8433 - val_loss: 1.1553 - val_accuracy: 0.7420\n",
      "Epoch 52/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.5092 - accuracy: 0.8432 - val_loss: 1.0304 - val_accuracy: 0.7686\n",
      "Epoch 53/80\n",
      "7560/7560 [==============================] - 96s 13ms/step - loss: 0.4994 - accuracy: 0.8461 - val_loss: 1.1337 - val_accuracy: 0.7461\n",
      "Epoch 54/80\n",
      "7560/7560 [==============================] - 98s 13ms/step - loss: 0.4917 - accuracy: 0.8482 - val_loss: 1.2583 - val_accuracy: 0.7205\n",
      "Epoch 55/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.4819 - accuracy: 0.8510 - val_loss: 1.1562 - val_accuracy: 0.7478\n",
      "Epoch 56/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.4796 - accuracy: 0.8520 - val_loss: 1.0962 - val_accuracy: 0.7569\n",
      "Epoch 57/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.4680 - accuracy: 0.8553 - val_loss: 1.1080 - val_accuracy: 0.7604\n",
      "Epoch 58/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.4654 - accuracy: 0.8561 - val_loss: 1.1116 - val_accuracy: 0.7562\n",
      "Epoch 59/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.4566 - accuracy: 0.8584 - val_loss: 1.1527 - val_accuracy: 0.7533\n",
      "Epoch 60/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.4493 - accuracy: 0.8605 - val_loss: 1.0829 - val_accuracy: 0.7654\n",
      "Epoch 61/80\n",
      "7560/7560 [==============================] - 98s 13ms/step - loss: 0.4534 - accuracy: 0.8597 - val_loss: 1.1323 - val_accuracy: 0.7605\n",
      "Epoch 62/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.4449 - accuracy: 0.8614 - val_loss: 1.2203 - val_accuracy: 0.7430\n",
      "Epoch 63/80\n",
      "7560/7560 [==============================] - 96s 13ms/step - loss: 0.4395 - accuracy: 0.8635 - val_loss: 1.1386 - val_accuracy: 0.7573\n",
      "Epoch 64/80\n",
      "7560/7560 [==============================] - 96s 13ms/step - loss: 0.4285 - accuracy: 0.8667 - val_loss: 1.0964 - val_accuracy: 0.7699\n",
      "Epoch 65/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.4282 - accuracy: 0.8665 - val_loss: 1.0500 - val_accuracy: 0.7786\n",
      "Epoch 66/80\n",
      "7560/7560 [==============================] - 100s 13ms/step - loss: 0.4216 - accuracy: 0.8678 - val_loss: 1.1560 - val_accuracy: 0.7595\n",
      "Epoch 67/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.4163 - accuracy: 0.8703 - val_loss: 1.1140 - val_accuracy: 0.7712\n",
      "Epoch 68/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.4133 - accuracy: 0.8702 - val_loss: 1.1266 - val_accuracy: 0.7657\n",
      "Epoch 69/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.4101 - accuracy: 0.8714 - val_loss: 1.0966 - val_accuracy: 0.7757\n",
      "Epoch 70/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.4092 - accuracy: 0.8728 - val_loss: 1.2136 - val_accuracy: 0.7462\n",
      "Epoch 71/80\n",
      "7560/7560 [==============================] - 96s 13ms/step - loss: 0.4019 - accuracy: 0.8743 - val_loss: 1.1280 - val_accuracy: 0.7678\n",
      "Epoch 72/80\n",
      "7560/7560 [==============================] - 97s 13ms/step - loss: 0.3980 - accuracy: 0.8745 - val_loss: 1.1504 - val_accuracy: 0.7672\n",
      "Epoch 73/80\n",
      "7560/7560 [==============================] - 96s 13ms/step - loss: 0.3917 - accuracy: 0.8775 - val_loss: 1.1242 - val_accuracy: 0.7731\n",
      "Epoch 74/80\n",
      "7560/7560 [==============================] - 94s 12ms/step - loss: 0.3878 - accuracy: 0.8778 - val_loss: 1.1290 - val_accuracy: 0.7716\n",
      "Epoch 75/80\n",
      "7560/7560 [==============================] - 93s 12ms/step - loss: 0.3858 - accuracy: 0.8789 - val_loss: 1.1464 - val_accuracy: 0.7724\n",
      "Epoch 76/80\n",
      "7560/7560 [==============================] - 94s 12ms/step - loss: 0.3834 - accuracy: 0.8800 - val_loss: 1.4463 - val_accuracy: 0.7156\n",
      "Epoch 77/80\n",
      "7560/7560 [==============================] - 94s 12ms/step - loss: 0.3797 - accuracy: 0.8806 - val_loss: 1.2326 - val_accuracy: 0.7505\n",
      "Epoch 78/80\n",
      "7560/7560 [==============================] - 93s 12ms/step - loss: 0.3767 - accuracy: 0.8822 - val_loss: 1.2066 - val_accuracy: 0.7640\n",
      "Epoch 79/80\n",
      "7560/7560 [==============================] - 92s 12ms/step - loss: 0.3768 - accuracy: 0.8815 - val_loss: 1.3917 - val_accuracy: 0.7284\n",
      "Epoch 80/80\n",
      "7560/7560 [==============================] - 93s 12ms/step - loss: 0.3709 - accuracy: 0.8839 - val_loss: 1.1849 - val_accuracy: 0.7727\n"
     ]
    }
   ],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping()\n",
    "\n",
    "# EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 0, mode = 'auto')\n",
    "hist = model.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), epochs=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13336\\3015319970.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'h5py' has no attribute 'File'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28180\\3692831719.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model/model_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\PCS\\anaconda3\\envs\\cuda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   2144\u001b[0m     \u001b[1;31m# pylint: enable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 2146\u001b[1;33m                     signatures, options, save_traces)\n\u001b[0m\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m   def save_weights(self,\n",
      "\u001b[1;32mc:\\Users\\PCS\\anaconda3\\envs\\cuda\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   if (save_format == 'h5' or\n\u001b[1;32m--> 133\u001b[1;33m       \u001b[1;33m(\u001b[0m\u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m       saving_utils.is_hdf5_filepath(filepath)):\n\u001b[0;32m    135\u001b[0m     \u001b[1;31m# TODO(b/130258301): add utility method for detecting model type.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'h5py' has no attribute 'File'"
     ]
    }
   ],
   "source": [
    "model.save('./model/model_1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
